From ceb2a16bfec86824c1dd7e7493bc6b7fd56acc00 Mon Sep 17 00:00:00 2001
From: Roman Stratiienko <r.stratiienko@gmail.com>
Date: Sun, 2 Oct 2022 17:14:06 +0300
Subject: [PATCH 01/13] minigbm: Use dmabuf inode as unique buffer id instead
 of handle

Handle has some limits and can't be used as unique buffer ID on systems
where display controller can scanout from CMA but GPU can work with both
CMA and VRAM.

Such systems have DRM/KMS and DRM/GPU drivers separated.
GBM frontend is always expecting handle for DRM/KMS driver.
In such system any attempt of importing the buffer with more
than 1 contiguous chunk into DRM/KMS driver will fail.

Using dma-buf inode as unique buffer ID is a common practice for
a last several years starting from [this kernel patch][1].

[1]: https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=ed63bb1d1f8469586006a9ca63c42344401aa2ab
Change-Id: Ic3a69010d5da2f866a2252fc7e9eb29d67f8e1ed
Signed-off-by: Roman Stratiienko <r.stratiienko@gmail.com>
---
 drv.c           | 35 +++++++++++++++++++++--------------
 drv.h           |  3 ++-
 drv_helpers.c   | 13 +++++++++++++
 drv_helpers.h   |  2 ++
 drv_priv.h      |  2 ++
 virtgpu_virgl.c |  8 ++++----
 6 files changed, 44 insertions(+), 19 deletions(-)

diff --git a/drv.c b/drv.c
index 462b763..83656a9 100644
--- a/drv.c
+++ b/drv.c
@@ -240,7 +240,7 @@ static void drv_bo_mapping_destroy(struct bo *bo)
 		while (idx < drv_array_size(drv->mappings)) {
 			struct mapping *mapping =
 			    (struct mapping *)drv_array_at_idx(drv->mappings, idx);
-			if (mapping->vma->handle != bo->handles[plane].u32) {
+			if (mapping->vma->inode != bo->inodes[plane]) {
 				idx++;
 				continue;
 			}
@@ -274,11 +274,16 @@ static void drv_bo_acquire(struct bo *bo)
 	pthread_mutex_lock(&drv->buffer_table_lock);
 	for (size_t plane = 0; plane < bo->meta.num_planes; plane++) {
 		uintptr_t num = 0;
+		if (!bo->inodes[plane]) {
+			int fd = drv_bo_get_plane_fd(bo, plane);
+			bo->inodes[plane] = drv_get_inode(fd);
+			close(fd);
+		}
 
-		if (!drmHashLookup(drv->buffer_table, bo->handles[plane].u32, (void **)&num))
-			drmHashDelete(drv->buffer_table, bo->handles[plane].u32);
+		if (!drmHashLookup(drv->buffer_table, bo->inodes[plane], (void **)&num))
+			drmHashDelete(drv->buffer_table, bo->inodes[plane]);
 
-		drmHashInsert(drv->buffer_table, bo->handles[plane].u32, (void *)(num + 1));
+		drmHashInsert(drv->buffer_table, bo->inodes[plane], (void *)(num + 1));
 	}
 	pthread_mutex_unlock(&drv->buffer_table_lock);
 }
@@ -297,11 +302,11 @@ static bool drv_bo_release(struct bo *bo)
 
 	pthread_mutex_lock(&drv->buffer_table_lock);
 	for (size_t plane = 0; plane < bo->meta.num_planes; plane++) {
-		if (!drmHashLookup(drv->buffer_table, bo->handles[plane].u32, (void **)&num)) {
-			drmHashDelete(drv->buffer_table, bo->handles[plane].u32);
+		if (!drmHashLookup(drv->buffer_table, bo->inodes[plane], (void **)&num)) {
+			drmHashDelete(drv->buffer_table, bo->inodes[plane]);
 
 			if (num > 1) {
-				drmHashInsert(drv->buffer_table, bo->handles[plane].u32,
+				drmHashInsert(drv->buffer_table, bo->inodes[plane],
 					      (void *)(num - 1));
 			}
 		}
@@ -309,7 +314,7 @@ static bool drv_bo_release(struct bo *bo)
 
 	/* The same buffer can back multiple planes with different offsets. */
 	for (size_t plane = 0; plane < bo->meta.num_planes; plane++) {
-		if (!drmHashLookup(drv->buffer_table, bo->handles[plane].u32, (void **)&num)) {
+		if (!drmHashLookup(drv->buffer_table, bo->inodes[plane], (void **)&num)) {
 			/* num is positive if found in the hashmap. */
 			pthread_mutex_unlock(&drv->buffer_table_lock);
 			return false;
@@ -421,6 +426,9 @@ struct bo *drv_bo_import(struct driver *drv, struct drv_import_fd_data *data)
 		return NULL;
 	}
 
+	for (plane = 0; plane < bo->meta.num_planes; plane++)
+		bo->inodes[plane] = drv_get_inode(data->fds[plane]);
+
 	drv_bo_acquire(bo);
 
 	bo->meta.format_modifier = data->format_modifier;
@@ -481,8 +489,7 @@ void *drv_bo_map(struct bo *bo, const struct rectangle *rect, uint32_t map_flags
 
 	for (i = 0; i < drv_array_size(drv->mappings); i++) {
 		struct mapping *prior = (struct mapping *)drv_array_at_idx(drv->mappings, i);
-		if (prior->vma->handle != bo->handles[plane].u32 ||
-		    prior->vma->map_flags != map_flags)
+		if (prior->vma->inode != bo->inodes[plane] || prior->vma->map_flags != map_flags)
 			continue;
 
 		if (rect->x != prior->rect.x || rect->y != prior->rect.y ||
@@ -496,8 +503,7 @@ void *drv_bo_map(struct bo *bo, const struct rectangle *rect, uint32_t map_flags
 
 	for (i = 0; i < drv_array_size(drv->mappings); i++) {
 		struct mapping *prior = (struct mapping *)drv_array_at_idx(drv->mappings, i);
-		if (prior->vma->handle != bo->handles[plane].u32 ||
-		    prior->vma->map_flags != map_flags)
+		if (prior->vma->inode != bo->inodes[plane] || prior->vma->map_flags != map_flags)
 			continue;
 
 		prior->vma->refcount++;
@@ -523,7 +529,8 @@ void *drv_bo_map(struct bo *bo, const struct rectangle *rect, uint32_t map_flags
 
 	mapping.vma->refcount = 1;
 	mapping.vma->addr = addr;
-	mapping.vma->handle = bo->handles[plane].u32;
+	mapping.vma->plane = plane;
+	mapping.vma->inode = bo->inodes[plane];
 	mapping.vma->map_flags = map_flags;
 
 success:
@@ -727,7 +734,7 @@ uint32_t drv_num_buffers_per_bo(struct bo *bo)
 
 	for (plane = 0; plane < bo->meta.num_planes; plane++) {
 		for (p = 0; p < plane; p++)
-			if (bo->handles[p].u32 == bo->handles[plane].u32)
+			if (bo->inodes[p] == bo->inodes[plane])
 				break;
 		if (p == plane)
 			count++;
diff --git a/drv.h b/drv.h
index dec43fc..b4966d0 100644
--- a/drv.h
+++ b/drv.h
@@ -109,7 +109,8 @@ struct drv_import_fd_data {
 struct vma {
 	void *addr;
 	size_t length;
-	uint32_t handle;
+	uint32_t plane;
+	uint32_t inode;
 	uint32_t map_flags;
 	int32_t refcount;
 	uint32_t map_strides[DRV_MAX_PLANES];
diff --git a/drv_helpers.c b/drv_helpers.c
index 7d0cebe..6ff1fc6 100644
--- a/drv_helpers.c
+++ b/drv_helpers.c
@@ -12,6 +12,7 @@
 #include <stdlib.h>
 #include <string.h>
 #include <sys/mman.h>
+#include <sys/stat.h>
 #include <sys/types.h>
 #include <unistd.h>
 #include <xf86drm.h>
@@ -601,3 +602,15 @@ void drv_resolve_format_and_use_flags_helper(struct driver *drv, uint32_t format
 		break;
 	}
 }
+
+uint32_t drv_get_inode(int dmabuf_fd)
+{
+	struct stat sb = { 0 };
+	int ret = 0;
+
+	ret = fstat(dmabuf_fd, &sb);
+	if (ret)
+		drv_loge("Failed to fstat dmabuf %d: %s\n", dmabuf_fd, strerror(errno));
+
+	return sb.st_ino;
+}
diff --git a/drv_helpers.h b/drv_helpers.h
index edb69bf..7dad5bd 100644
--- a/drv_helpers.h
+++ b/drv_helpers.h
@@ -48,4 +48,6 @@ void drv_resolve_format_and_use_flags_helper(struct driver *drv, uint32_t format
 					     uint64_t use_flags, uint32_t *out_format,
 					     uint64_t *out_use_flags);
 
+uint32_t drv_get_inode(int dmabuf_fd);
+
 #endif
diff --git a/drv_priv.h b/drv_priv.h
index 9fa84a5..a271e50 100644
--- a/drv_priv.h
+++ b/drv_priv.h
@@ -44,7 +44,9 @@ struct bo {
 	struct driver *drv;
 	struct bo_metadata meta;
 	bool is_test_buffer;
+	/* handles are mandatory only for SCANOUT buffers */
 	union bo_handle handles[DRV_MAX_PLANES];
+	uint32_t inodes[DRV_MAX_PLANES];
 	void *priv;
 };
 
diff --git a/virtgpu_virgl.c b/virtgpu_virgl.c
index a905d74..4863f60 100644
--- a/virtgpu_virgl.c
+++ b/virtgpu_virgl.c
@@ -834,7 +834,7 @@ static int virgl_bo_invalidate(struct bo *bo, struct mapping *mapping)
 	if (params[param_resource_blob].value && (bo->meta.tiling & VIRTGPU_BLOB_FLAG_USE_MAPPABLE))
 		return 0;
 
-	xfer.bo_handle = mapping->vma->handle;
+	xfer.bo_handle = bo->handles[mapping->vma->plane].u32;
 
 	if (mapping->rect.x || mapping->rect.y) {
 		/*
@@ -888,7 +888,7 @@ static int virgl_bo_invalidate(struct bo *bo, struct mapping *mapping)
 	// The transfer needs to complete before invalidate returns so that any host changes
 	// are visible and to ensure the host doesn't overwrite subsequent guest changes.
 	// TODO(b/136733358): Support returning fences from transfers
-	waitcmd.handle = mapping->vma->handle;
+	waitcmd.handle = bo->handles[mapping->vma->plane].u32;
 	ret = drmIoctl(bo->drv->fd, DRM_IOCTL_VIRTGPU_WAIT, &waitcmd);
 	if (ret) {
 		drv_loge("DRM_IOCTL_VIRTGPU_WAIT failed with %s\n", strerror(errno));
@@ -916,7 +916,7 @@ static int virgl_bo_flush(struct bo *bo, struct mapping *mapping)
 	if (params[param_resource_blob].value && (bo->meta.tiling & VIRTGPU_BLOB_FLAG_USE_MAPPABLE))
 		return 0;
 
-	xfer.bo_handle = mapping->vma->handle;
+	xfer.bo_handle = bo->handles[mapping->vma->plane].u32;
 
 	if (mapping->rect.x || mapping->rect.y) {
 		/*
@@ -966,7 +966,7 @@ static int virgl_bo_flush(struct bo *bo, struct mapping *mapping)
 	// buffer, we need to wait for the transfer to complete for consistency.
 	// TODO(b/136733358): Support returning fences from transfers
 	if (bo->meta.use_flags & BO_USE_NON_GPU_HW) {
-		waitcmd.handle = mapping->vma->handle;
+		waitcmd.handle = bo->handles[mapping->vma->plane].u32;
 
 		ret = drmIoctl(bo->drv->fd, DRM_IOCTL_VIRTGPU_WAIT, &waitcmd);
 		if (ret) {
-- 
2.37.2

